{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## My Spotify Wrapped Trends, since 2018\n",
    "\n",
    "This is a notebook that performs some basic data processing operations on my own Spotify Wrapped playlists from 2018 (when I started using Spotify). \n",
    "\n",
    "*Note on Fetching Playlist Data:*\n",
    "\n",
    "Fetching the data from Spotify's API is done using the `spotify` Python Library. Being an asynchronous implementation of the API, it didn't play too nice with Jupyter in my experience, so it has been separately implemented in `playlists.py`. By default, running the script returns `list.csv`, which is used as the data source in this notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import hashlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accessing csv (created by playlists.py script)\n",
    "\n",
    "file = \"list.csv\"\n",
    "df = pd.read_csv(file)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Processing\n",
    "\n",
    "##### Creating 'song_id' column:\n",
    "\n",
    "The CSV is all populated with datapoints directly fetched from the API. We must do some cleaning and other processing for our purposes.\n",
    "\n",
    "1. Creating a 'combined' column, and then dropping it: There are some tracks in these playlists that are the exact same songs and performances, but have different Spotify IDs<sup>[1]</sup>. So we needed an id of our own, created by the concatenation of the song name and artist names. By making this field all lowercase, we also avoid another edge case<sup>[2]</sup> Not the most precise implementation<sup>[3]</sup>, but it works for our use case. \n",
    "\n",
    "2. The 'combined' column is then hashed to create 'song_id'. There is not much reason to hash the data; there can be any alternative method to make up an identifier of this data, but hashing in this case is more straightforward to create unique values from the 'combined' field (see [2])\n",
    "\n",
    "\n",
    "<sup><sub>[1] Possibly being Single releases vs. Album tracks, etc.</sub></sup>\n",
    "\n",
    "<sup><sub>[2] Some tracks can have some words capitalised or not (\"the\" vs. \"The\"), despite being the same tracks.</sub></sup>\n",
    "\n",
    "<sup><sub>[3] Re-released music with changed song names (yes, this is the \"(Taylor's Version)\" edge case) would require you to match the titles in the DataFrame</sub></sup>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine \"name\" and \"artists\" columns into a new column \"combined\"\n",
    "df['combined'] = (df['name'] + ' - ' + df['artists']).str.lower() # addressing the \"the\",\"The\" issue\n",
    "\n",
    "# Hash the combined values to create a unique identifier - some songs have different spotify IDs but are the exact same track\n",
    "df['song_id'] = df['combined'].apply(lambda x: hashlib.md5(x.encode()).hexdigest())\n",
    "\n",
    "df = df.drop(columns=['combined'])\n",
    "# might need some further wrangling for tv tracks later - keeping older tracks as it is\n",
    "# also, Between The Bars for example has two entries, not merged ('the' and \"The\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Pivoting the DataFrame:\n",
    "\n",
    "This is where song_id comes in handy. Songs appearing in more than one Wrapped lists have the same ID, so by pivoting over song_id as our index, for all the 'year' columns, we get a more manuverable table which we can use for all further processing. This creates a table with only song_id's and the yearly ranks. Songs that don't appear in some year's list get the value ``0`` for that year.\n",
    "\n",
    "We add the song name (``name``) and artist name (``artists``) back in the next step, to bring together all distinct songs, despite them having different Spotify IDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pivoting table, for years on song_id\n",
    "\n",
    "years = df['year'].unique().tolist() # final, don't redefine\n",
    "pivot_df = df.pivot_table(index='song_id', columns='year', values='index', fill_value=0)\n",
    "\n",
    "# Reset the index to make 'song_id' a regular column\n",
    "pivot_df = pivot_df.reset_index()\n",
    "\n",
    "# convert floats to int to make data cleaner\n",
    "pivot_df[years] = pivot_df[years].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding back song names and artists on song_id values\n",
    "\n",
    "if df['song_id'].duplicated().any():\n",
    "    df = df.drop_duplicates(subset='song_id')\n",
    "    \n",
    "pivot_df = pd.merge(pivot_df, df[['name', 'artists', 'song_id']], on='song_id', how='left')\n",
    "pivot_df # final working dataset - data cleaned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Creating 'list_appearances' column: How many yearly lists is each song in?\n",
    "\n",
    "The ``'list_appearances'`` column is added to view at-a-glance how many times has a track appeared in a yearly Wrapped list. It simply checks how many columns for each row have a non-zero value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# counting number of appearances for each song in the lists\n",
    "pivot_df['list_appearances'] = pivot_df[years].apply(lambda row: row.astype(bool).sum(), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Finishing up Data Processing:\n",
    "\n",
    "Just rearranging our data columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rearranging df to have all year indices to the end\n",
    "cols = ['name', 'artists', 'song_id', 'list_appearances'] + years\n",
    "pivot_df = pivot_df[cols]\n",
    "pivot_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# song_artists = list of each unique artist and how many songs they have on the list\n",
    "song_artists = pivot_df['artists'].value_counts()\n",
    "\n",
    "print(song_artists.loc['Elliott Smith'])\n",
    "# pivot_df[pivot_df['artists'] == 'Tame Impala']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year_to_refer = 2019\n",
    "artist_to_refer = 'Daft Punk'\n",
    "pivot_df[(pivot_df['artists'] == artist_to_refer) & (pivot_df[year_to_refer] > 0)][['name', 'artists', year_to_refer]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# present in 3 or more lists\n",
    "\n",
    "three_df = pivot_df[pivot_df['list_appearances'] >= 3]\n",
    "\n",
    "three_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# present in 2 or more lists\n",
    "\n",
    "two_df = pivot_df[pivot_df['list_appearances'] >= 2]\n",
    "\n",
    "two_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# present in 4 or more lists\n",
    "\n",
    "four_df = pivot_df[pivot_df['list_appearances'] >= 4]\n",
    "\n",
    "four_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one timers\n",
    "\n",
    "one_df = pivot_df[pivot_df['list_appearances'] == 1]\n",
    "\n",
    "one_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generic line graph maker - for reference\n",
    "\n",
    "sample_df = three_df\n",
    "years = sample_df.columns[4:]\n",
    "\n",
    "for index, row in sample_df.iterrows():\n",
    "    non_zero_values = [(year, value) for year, value in zip(years, row[4:]) if value != 0]\n",
    "    if non_zero_values:\n",
    "        years_non_zero, values_non_zero = zip(*non_zero_values)\n",
    "        plt.plot(years_non_zero, values_non_zero, marker='D', label=row['name'])\n",
    "        \n",
    "# Adding title and labels\n",
    "plt.title('Line Graph for Songs Over Years')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Rank in Wrapped Playlist')\n",
    "\n",
    "plt.xticks(range(int(min(years)), int(max(years)) + 1))\n",
    "\n",
    "# Adding a legend to identify each line\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.gca().invert_yaxis()\n",
    "\n",
    "# Display the graph\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hit wonders, top 10 to nowhere in the following list\n",
    "# starting with year-wise to-and-from\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"recovering tracks - with >= 3 appearances, the ones that went up over a year in ranks\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How are the 2018 tracks doing in subsequent lists (if they made it in any lists afterwards,\n",
    "# and the ones that didn't, where were they ranked?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# artists' best years, most common apperances, ups-and-downs over the years \n",
    "# an illustration: MGMT - 2021 super dense, fell off after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 or more appearances, graphing them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
