{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## My Spotify Wrapped Trends, since 2018\n",
    "\n",
    "This is a notebook that performs some basic data processing operations on my own Spotify Wrapped playlists from 2018 (when I started using Spotify). \n",
    "\n",
    "*Note on Fetching Playlist Data:*\n",
    "\n",
    "Fetching the data from Spotify's API is done using the `spotify` Python Library. Being an asynchronous implementation of the API, it didn't play too nice with Jupyter in my experience, so it has been separately implemented in `playlists.py`. By default, running the script returns `list.csv`, which is used as the data source in this notebook.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialisation\n",
    "\n",
    "Loading libraries and data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import hashlib\n",
    "import textwrap\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.set_option('mode.chained_assignment', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accessing csv (created by playlists.py script)\n",
    "\n",
    "file = \"list.csv\"\n",
    "df = pd.read_csv(file)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Processing\n",
    "\n",
    "#### Creating 'song_id' column:\n",
    "\n",
    "The CSV is all populated with datapoints directly fetched from the API. We must do some cleaning and other processing for our purposes.\n",
    "\n",
    "1. Creating a 'combined' column, and then dropping it: There are some tracks in these playlists that are the exact same songs and performances, but have different Spotify IDs<sup>[1]</sup>. So we needed an id of our own, created by the concatenation of the song name and artist names. By making this field all lowercase, we also avoid another edge case<sup>[2]</sup> Not the most precise implementation<sup>[3]</sup>, but it works for our use case. \n",
    "\n",
    "2. The 'combined' column is then hashed to create 'song_id'. There is not much reason to hash the data; there can be any alternative method to make up an identifier of this data, but hashing in this case is more straightforward to create unique values from the 'combined' field (see [2])\n",
    "\n",
    "\n",
    "<sup><sub>[1] Possibly being Single releases vs. Album tracks, etc.</sub></sup>\n",
    "\n",
    "<sup><sub>[2] Some tracks can have some words capitalised or not (\"the\" vs. \"The\"), despite being the same tracks.</sub></sup>\n",
    "\n",
    "<sup><sub>[3] Re-released music with changed song names (yes, this is the \"(Taylor's Version)\" edge case) would require you to match the titles in the DataFrame</sub></sup>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine \"name\" and \"artists\" columns into a new column \"combined\"\n",
    "df['combined'] = (df['name'] + ' - ' + df['artists']).str.lower() # addressing the \"the\",\"The\" issue\n",
    "\n",
    "# Hash the combined values to create a unique identifier - some songs have different spotify IDs but are the exact same track\n",
    "df['song_id'] = df['combined'].apply(lambda x: hashlib.md5(x.encode()).hexdigest())\n",
    "\n",
    "df = df.drop(columns=['combined'])\n",
    "# might need some further wrangling for tv tracks later - keeping older tracks as it is"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pivoting the DataFrame:\n",
    "\n",
    "This is where song_id comes in handy. Songs appearing in more than one Wrapped lists have the same ID, so by pivoting over song_id as our index, for all the 'year' columns, we get a more manuverable table which we can use for all further processing. This creates a table with only song_id's and the yearly ranks. Songs that don't appear in some year's list get the value ``0`` for that year.\n",
    "\n",
    "We add the song name (``name``) and artist name (``artists``) back in the next step, to bring together all distinct songs, despite them having different Spotify IDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pivoting table, for years on song_id\n",
    "\n",
    "years = df['year'].unique().tolist() # final, don't redefine - useful later as well\n",
    "song_info_short = ['name', 'artists']\n",
    "pivot_df = df.pivot_table(index='song_id', columns='year', values='index', fill_value=0)\n",
    "\n",
    "# Reset the index to make 'song_id' a regular column\n",
    "pivot_df = pivot_df.reset_index()\n",
    "\n",
    "# convert floats to int to make data cleaner\n",
    "pivot_df[years] = pivot_df[years].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding back song names and artists on song_id values\n",
    "\n",
    "if df['song_id'].duplicated().any():\n",
    "    df = df.drop_duplicates(subset='song_id')\n",
    "    \n",
    "pivot_df = pd.merge(pivot_df, df[['name', 'artists', 'song_id']], on='song_id', how='left')\n",
    "pivot_df # working dataset - data cleaned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating 'list_appearances' column: How many yearly lists is each song in?\n",
    "\n",
    "The ``'list_appearances'`` column is added to view at-a-glance how many times has a track appeared in a yearly Wrapped list. It simply checks how many columns for each row have a non-zero value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# counting number of appearances for each song in the lists\n",
    "pivot_df['list_appearances'] = pivot_df[years].apply(lambda row: row.astype(bool).sum(), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finishing up Data Processing:\n",
    "\n",
    "Just rearranging our data columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rearranging df to have all year indices to the end\n",
    "cols = ['name', 'artists', 'song_id', 'list_appearances'] + years\n",
    "pivot_df = pivot_df[cols]\n",
    "pivot_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Analysis\n",
    "\n",
    "#### Appearances by Artists, and their multiple entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of each unique artist and how many songs they have on the list\n",
    "song_artists = pivot_df['artists'].value_counts()\n",
    "\n",
    "# Keeping the ones with multiple entrants in a separate series\n",
    "multi_song_artists = song_artists[song_artists > 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Creating a bar graph of all the artists with multiple entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a bar chart to visualise all multiple-entrant artists\n",
    "\n",
    "grouped_multi_artists = multi_song_artists.groupby(multi_song_artists).apply(lambda x: ', '.join(x.index))\n",
    "\n",
    "plt.figure(figsize=(12, 14))\n",
    "plt.barh(grouped_multi_artists, grouped_multi_artists.index, color='lightgreen')\n",
    "\n",
    "plt.xlabel('Number of Songs')\n",
    "plt.ylabel('Artists')\n",
    "plt.title('Track Counts by Artists')\n",
    "\n",
    "plt.yticks(rotation=0, ha='right', wrap=True)\n",
    "plt.xticks(range(0, max(grouped_multi_artists.index) + 1, 1))\n",
    "plt.tight_layout()\n",
    "\n",
    "for index, value in enumerate(grouped_multi_artists.index):\n",
    "    plt.text(value + 0.25, index, str(value), va='center', ha='center', fontsize=10)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### One-year Dream Runs\n",
    "\n",
    "Ever had a very ephemeral earworm? A song that you listened to a whole lot, but only for a short while? Or, songs that were very \"of a particular time\" for you? They frequently end up in the Top 10 for me each year, and then completely vanish from my Wrapped the next year. Here's some data analysis on them! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a df mask to get each year's top 10\n",
    "\n",
    "# For all years, create a mask for all rows with rank < 10 in any year\n",
    "top_10s = pivot_df[pivot_df[years].apply(lambda x: x.between(1, 10)).any(axis=1)]\n",
    "\n",
    "top_10s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering all top 10s which vanished from the list the next year\n",
    "\n",
    "dream_runs = pd.DataFrame()\n",
    "\n",
    "def one_year_filter(row):\n",
    "    for year in years[:-1]: # TODO: go by index in years, in case any year is skipped\n",
    "        if ((row[year] < 10 and row[year] > 0) and row[year + 1] == 0): \n",
    "            return year\n",
    "    return None\n",
    "\n",
    "dream_runs = (top_10s.copy()\n",
    "              .assign(dream_year=top_10s.apply(one_year_filter, axis=1))\n",
    "              .dropna(subset=['dream_year'])\n",
    "              .astype({'dream_year': int})\n",
    "              .drop(columns=['song_id', 'list_appearances'])\n",
    "              .sort_values(by='dream_year'))\n",
    "dream_runs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Plot to visualise the Top 10 \"dream run\" tracks from each year recorded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scatter plot to visualise dream run tracks\n",
    "\n",
    "scatter_dream_runs = dream_runs.copy()\n",
    "\n",
    "scatter_dream_runs['pos'] = scatter_dream_runs.apply(lambda row: row[row['dream_year']], axis=1)\n",
    "scatter_dream_runs['anno'] = scatter_dream_runs['artists'] + ' - ' + scatter_dream_runs['name']\n",
    "scatter_dream_runs = scatter_dream_runs.drop(columns=years)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(scatter_dream_runs['dream_year'], scatter_dream_runs['pos'], c='#00ed00')\n",
    "\n",
    "for index, row in scatter_dream_runs.iterrows():\n",
    "    wrap = textwrap.fill(row['anno'], width=20)\n",
    "    plt.annotate(wrap, (row['dream_year'], row['pos']), textcoords=\"offset points\", xytext=(0, 10), ha='center', fontsize=8)\n",
    "\n",
    "plt.xlabel('Years')\n",
    "plt.ylabel('Ranks')\n",
    "plt.title('One-Year Dream Runs')\n",
    "\n",
    "plt.yticks(range(1, 11, 1))\n",
    "plt.xticks(range(min(scatter_dream_runs['dream_year']), max(scatter_dream_runs['dream_year']) + 1, 1))\n",
    "\n",
    "plt.margins(x=0.2, y=0.1)\n",
    "plt.grid(axis='x')\n",
    "\n",
    "plt.gca().spines['top'].set_visible(False)\n",
    "plt.gca().spines['right'].set_visible(False)\n",
    "plt.gca().invert_yaxis()\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### On The Up\n",
    "\n",
    "Tracks that ended up higher in a list than the previous year's list on one occasion, or returned to the lists after being absent for a year or more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"recovering tracks - with >= 2 appearances, the ones that went up over a year in ranks, \n",
    "# or returned to the lists after being absent\n",
    "\n",
    "two_df = pivot_df[pivot_df['list_appearances'] >= 2]\n",
    "# two_df\n",
    "\n",
    "# each row each year, if the next is larger than the previous, recovery, else not...?\n",
    "recover_df = pd.DataFrame(columns=two_df.columns)\n",
    "# print(years)\n",
    "\n",
    "for index, row in two_df.iterrows():\n",
    "    off_list = False\n",
    "    for i in range(len(years) - 1):\n",
    "        current_year = years[i]\n",
    "        next_year = years[i + 1]\n",
    "\n",
    "        curr_value = row[current_year]\n",
    "        next_value = row[next_year]\n",
    "        \n",
    "        if curr_value != 0 and next_value == 0:\n",
    "            off_list = True\n",
    "        if (next_value < curr_value or off_list) and next_value != 0:\n",
    "            recover_df = pd.concat([recover_df, row.to_frame().T], ignore_index=True)\n",
    "            break\n",
    "\n",
    "recover_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# viz. for recovering tracks and by how much did each go up (exclude off_list tracks)\n",
    "# maybe expand on recover_df, add params ('off_list/climbed', 'upward delta (if climbed)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First to Last Time\n",
    "\n",
    "A closer look at your first Wrapped playlist. What tracks didn't return to the playlists ever again, which ones did, and which ones still found place in your latest Wrapped playlist!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How are the tracks from your first Wrapped doing in subsequent lists (if they made it in any lists afterwards,\n",
    "# and the ones that didn't, where were they ranked?)\n",
    "\n",
    "df_first = pivot_df[pivot_df[years[0]] > 0]\n",
    "first_none_mask = df_first[years[1:]].eq(0).all(axis=1)\n",
    "\n",
    "df_first_none = df_first[first_none_mask]\n",
    "df_first_not_none = df_first[~first_none_mask]\n",
    "\n",
    "print(f\"Songs from {years[0]}'s Wrapped that were in subsequent lists = {df_first_not_none.shape[0]}\")\n",
    "print(f\"Songs from {years[0]}'s Wrapped that were not in subsequent lists = {df_first_none.shape[0]}\")\n",
    "\n",
    "# TODO: (new) per-playlist attrition (needs more determination, what about previous lists)\n",
    "# Songs present in the last Wrapped \n",
    "\n",
    "\n",
    "# df_first_not_none\n",
    "# df_first.sort_values(by=years[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Songs only appearing in the following list\n",
    "\n",
    "df_only_next = df_first_not_none[df_first_not_none[years[2:]].eq(0).all(axis=1)]\n",
    "\n",
    "df_only_next['delta'] = df_only_next.apply(lambda row: row[years[1]] - row[years[0]], axis=1)\n",
    "df_only_next[['name', 'artists', years[0], years[1], 'delta']].sort_values('delta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls = list(range(1, 5, -1))\n",
    "print(ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Songs from the first Wrapped present in the last Wrapped \n",
    "\n",
    "df_first_not_none[df_first_not_none[years[-1]] > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## under development sections:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEV\n",
    "\n",
    "top_10s[(top_10s[2019] > 0) & (top_10s[2019] <= 10)].sort_values(by=2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_10s[top_10s[years].eq(3).any(axis=1)]\n",
    "\n",
    "# df_first_not_none[df_first_not_none[years[2:]].eq(0).all(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year_to_refer = 2022\n",
    "artist_to_refer = 'Wolfgang Amadeus Mozart'\n",
    "pivot_df[(pivot_df['artists'] == artist_to_refer) & (pivot_df[year_to_refer] > 0)][['name', 'artists', year_to_refer]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_df[(pivot_df['artists'] == \"Charli XCX\")] #[['name', 'artists']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_df[pivot_df['name'] == 'pink diamond']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# present in 3 or more lists\n",
    "\n",
    "three_df = pivot_df[pivot_df['list_appearances'] >= 3]\n",
    "\n",
    "three_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# present in 2 or more lists\n",
    "\n",
    "two_df = pivot_df[pivot_df['list_appearances'] >= 2]\n",
    "\n",
    "two_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# present in 4 or more lists\n",
    "\n",
    "four_df = pivot_df[pivot_df['list_appearances'] >= 4]\n",
    "\n",
    "four_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one timers\n",
    "\n",
    "one_df = pivot_df[pivot_df['list_appearances'] == 1]\n",
    "\n",
    "one_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generic line graph maker - for reference\n",
    "\n",
    "sample_df = three_df\n",
    "years = sample_df.columns[4:]\n",
    "\n",
    "for index, row in sample_df.iterrows():\n",
    "    non_zero_values = [(year, value) for year, value in zip(years, row[4:]) if value != 0]\n",
    "    if non_zero_values:\n",
    "        years_non_zero, values_non_zero = zip(*non_zero_values)\n",
    "        plt.plot(years_non_zero, values_non_zero, marker='D', label=row['name'])\n",
    "        \n",
    "# Adding title and labels\n",
    "# plt.figure(figsize=(15, 15))\n",
    "\n",
    "plt.title('Line Graph for Songs Over Years')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Rank in Wrapped Playlist')\n",
    "\n",
    "plt.xticks(range(int(min(years)), int(max(years)) + 1))\n",
    "\n",
    "# Adding a legend to identify each line\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.gca().invert_yaxis()\n",
    "\n",
    "# Display the graph\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some sort of statistical metric to track consistency of the track in the rankings where it's present in >3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one list to another: which adjacent have the greatest overlap?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (merge with recovering tracks) comebacks (in list -> 0 -> back in list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# artists' best years, most common apperances, ups-and-downs over the years \n",
    "# an illustration: MGMT - 2021 super dense, fell off after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 or more appearances, graphing them"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
